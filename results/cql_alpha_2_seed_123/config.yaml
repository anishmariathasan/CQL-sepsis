algorithm:
  activation: relu
  alpha: 2.0
  batch_size: 256
  gamma: 0.99
  grad_clip: 1.0
  hidden_dim: 256
  learning_rate: 0.0003
  name: cql
  num_layers: 2
  tau: 0.005
  use_double_dqn: true
dataset:
  buffer_capacity: 1000000
  normalize_rewards: false
deterministic: true
environment:
  action_dim: 25
  name: Sepsis-v0
  state_dim: 716
  use_one_hot: false
evaluation:
  n_episodes: 100
  seeds:
  - 0
  - 1
  - 2
  - 3
  - 4
  use_action_masking: true
logging:
  log_dir: results/logs
  use_tensorboard: true
  use_wandb: false
  wandb_entity: null
  wandb_project: cql-sepsis
seed: 123
training:
  checkpoint_frequency: 10000
  eval_frequency: 5000
  log_frequency: 100
  n_iterations: 100000
  warmup_steps: 0
